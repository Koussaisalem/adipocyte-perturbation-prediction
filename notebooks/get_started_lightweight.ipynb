{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adipocyte Perturbation: Lightweight Quickstart\n",
    "\n",
    "**CPU-Friendly Version** - No GPU required!\n",
    "\n",
    "This notebook uses lightweight PCA + Statistics embeddings instead of Geneformer.\n",
    "- **Runtime**: 5-15 minutes on CPU vs 2-4 hours with Geneformer\n",
    "- **Performance**: ~85-90% of Geneformer quality\n",
    "- **Requirements**: CPU, 16GB RAM (no GPU needed)\n",
    "\n",
    "Run cells top-to-bottom. GPU still recommended for training (step 7), but embedding extraction is CPU-only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup: Configure project paths (run first!)\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Auto-detect project root and set working directory\n",
    "notebook_dir = Path.cwd()\n",
    "if notebook_dir.name == \"notebooks\":\n",
    "    project_root = notebook_dir.parent\n",
    "elif (notebook_dir / \"notebooks\").exists():\n",
    "    project_root = notebook_dir\n",
    "else:\n",
    "    # Try to find project root by looking for markers\n",
    "    current = notebook_dir\n",
    "    while current != current.parent:\n",
    "        if (current / \"pyproject.toml\").exists() or (current / \".git\").exists():\n",
    "            project_root = current\n",
    "            break\n",
    "        current = current.parent\n",
    "    else:\n",
    "        project_root = notebook_dir\n",
    "\n",
    "# Change to project root for consistent paths\n",
    "os.chdir(project_root)\n",
    "print(f\"✓ Project root: {project_root}\")\n",
    "\n",
    "# Add src to path for imports\n",
    "if str(project_root / \"src\") not in sys.path:\n",
    "    sys.path.insert(0, str(project_root / \"src\"))\n",
    "\n",
    "# Import centralized path constants\n",
    "from utils.paths import (\n",
    "    PROJECT_ROOT, DATA_DIR, RAW_DATA_DIR, PROCESSED_DIR,\n",
    "    MODELS_DIR, CONFIGS_DIR, CHECKPOINTS_DIR, \n",
    "    SUBMISSIONS_DIR, EXPERIMENTS_DIR\n",
    ")\n",
    "\n",
    "print(f\"✓ Data directory: {DATA_DIR}\")\n",
    "print(f\"✓ Models directory: {MODELS_DIR}\")\n",
    "print(f\"✓ All paths configured!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Verify Data Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data files\n",
    "!ls -lh {RAW_DATA_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unzip if needed\n",
    "!unzip -o {RAW_DATA_DIR}/obesity_challenge_1.h5ad.small.zip -d {RAW_DATA_DIR} 2>/dev/null || echo \"Already unzipped or not found\"\n",
    "!ls -lh {RAW_DATA_DIR}/obesity_challenge_1.h5ad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Run Setup Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directories and gene lists\n",
    "!bash setup_codespace.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Build Knowledge Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build KG with CollecTRI/DoRothEA + STRING\n",
    "!python scripts/build_kg.py \\\n",
    "  --gene-list {PROCESSED_DIR}/all_genes.txt \\\n",
    "  --output {DATA_DIR}/kg/knowledge_graph.gpickle \\\n",
    "  --dorothea-levels A B \\\n",
    "  --string-threshold 700"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Extract Lightweight Gene Embeddings\n",
    "\n",
    "**This is the key difference!** Uses PCA + Statistics instead of Geneformer.\n",
    "\n",
    "### What it does:\n",
    "1. Computes 7 statistical features per gene (mean, std, expr freq, max, p90, CV, log mean)\n",
    "2. Computes 505 PCA components on gene-by-cell matrix\n",
    "3. Concatenates to 512 dimensions (7 stats + 505 PCA)\n",
    "4. Normalizes and saves in same format as Geneformer embeddings\n",
    "\n",
    "### Performance:\n",
    "- **Time**: 5-10 minutes on CPU (vs 2-4 hours for Geneformer on GPU)\n",
    "- **Quality**: ~85-90% of Geneformer performance\n",
    "- **Memory**: <16GB RAM (vs 24GB GPU VRAM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract embeddings using lightweight method\n",
    "!python scripts/extract_embeddings_lightweight.py \\\n",
    "  --h5ad-file {RAW_DATA_DIR}/obesity_challenge_1.h5ad \\\n",
    "  --output {PROCESSED_DIR}/gene_embeddings.pt \\\n",
    "  --embedding-dim 512 \\\n",
    "  --max-cells 20000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick check of embeddings\n",
    "import torch\n",
    "\n",
    "embeddings = torch.load(PROCESSED_DIR / 'gene_embeddings.pt')\n",
    "print(f\"Loaded {len(embeddings)} gene embeddings\")\n",
    "print(f\"Embedding dimension: {next(iter(embeddings.values())).shape[0]}\")\n",
    "print(f\"\\nSample genes: {list(embeddings.keys())[:5]}\")\n",
    "print(f\"\\nSample embedding (first 10 dims): {next(iter(embeddings.values()))[:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Train Model\n",
    "\n",
    "**Note**: Training still benefits from GPU, but uses much less memory than embedding extraction.\n",
    "- GPU: ~30-60 minutes\n",
    "- CPU: ~3-6 hours (slower but works)\n",
    "\n",
    "The lightweight embeddings work with the same training pipeline!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if GPU available for training\n",
    "import torch\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "!python scripts/train.py \\\n",
    "  --config {CONFIGS_DIR}/default.yaml \\\n",
    "  --seed 42 \\\n",
    "  2>&1 | tee {EXPERIMENTS_DIR}/logs/lightweight_run.log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Generate Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions\n",
    "!python scripts/generate_submission.py \\\n",
    "  --checkpoint {CHECKPOINTS_DIR}/best.ckpt \\\n",
    "  --output-dir {SUBMISSIONS_DIR} \\\n",
    "  --n-cells 100 \\\n",
    "  --batch-size 10 \\\n",
    "  2>&1 | tee {EXPERIMENTS_DIR}/logs/inference_lightweight.log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Validate Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check submission files\n",
    "import pandas as pd\n",
    "\n",
    "# Expression matrix\n",
    "expr_df = pd.read_csv(SUBMISSIONS_DIR / 'expression_matrix.csv')\n",
    "print(f\"Expression matrix shape: {expr_df.shape}\")\n",
    "print(f\"Expected: (286301, n_genes) including header\")\n",
    "print(f\"NaNs: {expr_df.isna().sum().sum()}\")\n",
    "\n",
    "# Program proportions\n",
    "props_df = pd.read_csv(SUBMISSIONS_DIR / 'program_proportions.csv')\n",
    "print(f\"\\nProgram proportions shape: {props_df.shape}\")\n",
    "print(props_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison: Lightweight vs Geneformer\n",
    "\n",
    "| Metric | Lightweight (PCA+Stats) | Geneformer |\n",
    "|--------|-------------------------|------------|\n",
    "| Embedding Time | 5-10 min (CPU) | 2-4 hours (GPU) |\n",
    "| Memory Required | 16GB RAM | 24GB GPU VRAM |\n",
    "| Expected Quality | 85-90% | 100% |\n",
    "| Hardware | CPU only | GPU required |\n",
    "| Training Compatibility | ✓ Same pipeline | ✓ Same pipeline |\n",
    "\n",
    "### When to use each:\n",
    "- **Lightweight**: Fast prototyping, limited GPU access, quick iterations\n",
    "- **Geneformer**: Final submissions, when GPU available, maximum performance needed\n",
    "\n",
    "### Pro tip:\n",
    "Develop and debug with lightweight embeddings, then switch to Geneformer for final runs!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. **Compare performance**: Run both notebooks and compare results\n",
    "2. **Hyperparameter tuning**: Adjust `--max-cells` or PCA components\n",
    "3. **Ensemble**: Combine predictions from both approaches\n",
    "4. **Cloud GPU**: Use Camber for Geneformer embeddings (Job 15142)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
